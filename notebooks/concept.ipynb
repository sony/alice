{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting CUDA device 1 with 48656 MiB free memory and 0% utilization\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if '_cwd_set' not in locals(): locals()['_cwd_set'] = os.chdir(os.path.dirname(os.getcwd()))\n",
    "import omnifig as fig\n",
    "fig.initialize()\n",
    "from src.jimports import *\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score, precision_recall_curve\n",
    "# for all stats at once\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from src.util import set_default_device, repo_root, data_root\n",
    "from src.interventions import ClassLevelLabelIntervention\n",
    "from src.dataset import RawCOCO, SimpleCOCO, RawCOCOCaptions, COCOCaptions, COCO, MNIST\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.optimize import root_scalar\n",
    "from scipy.stats import norm\n",
    "from src.baselines import ConceptAlgebra\n",
    "from matplotlib import patches as mpatches\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "device = set_default_device();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def roc_threshold(positives, negatives):\n",
    "    \"\"\"\n",
    "    Compute the optimal threshold using the ROC curve.\n",
    "    \n",
    "    Args:\n",
    "        positives: Array of data points from the positive class.\n",
    "        negatives: Array of data points from the negative class.\n",
    "\n",
    "    Returns:\n",
    "        Optimal threshold (float) based on the ROC curve.\n",
    "    \"\"\"\n",
    "    y_true = np.concatenate([np.ones(len(positives)), np.zeros(len(negatives))])\n",
    "    y_scores = np.concatenate([positives, negatives])\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    return thresholds[optimal_idx]\n",
    "\n",
    "def bayes_threshold(positives, negatives):\n",
    "    \"\"\"\n",
    "    Compute the Bayes threshold using the intersection of Gaussian PDFs.\n",
    "    Assumes both distributions are Gaussian.\n",
    "\n",
    "    Args:\n",
    "        positives: Array of data points from the positive class.\n",
    "        negatives: Array of data points from the negative class.\n",
    "\n",
    "    Returns:\n",
    "        Bayes threshold (float).\n",
    "    \"\"\"\n",
    "    m1, s1 = np.mean(positives), np.std(positives)\n",
    "    m0, s0 = np.mean(negatives), np.std(negatives)\n",
    "\n",
    "    def pdf_diff(x):\n",
    "        return norm.pdf(x, loc=m1, scale=s1) - norm.pdf(x, loc=m0, scale=s0)\n",
    "\n",
    "    result = root_scalar(pdf_diff, bracket=[m0, m1], method='brentq')\n",
    "    return result.root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fullddata = COCO(eval_split=-0.1)\n",
    "syscfg = fig.create_config('h/ws2')\n",
    "syscfg.silent=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = '/data/felix/cache/checkpoints/vae128_coco_20250116_222421/ckpt_100000'\n",
    "loc = '/data/felix/cache/checkpoints/ae128_coco_20250114_230254/ckpt_020000/'\n",
    "loc = '/data/felix/cache/checkpoints/sae128_coco_20250118_213955/ckpt_100000'\n",
    "loc = '/ssd/felix/cache/checkpoints/sae512_coco_20250128_121655/ckpt_010000'\n",
    "loc = Path(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = fig.create_config(*'h/ws2 a/wide norm m/ced d/coco-img'.split(), **{'latent-dim': 512, 'classifier.dropout': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/workspace/clones/omni-learn/omnilearn/machines.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(path, map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "trainer = cfg.pull('trainer', silent=True)\n",
    "model = trainer.model\n",
    "traindataset = cfg.pull('dataset', silent=True)\n",
    "valdataset = traindataset.as_eval()\n",
    "traindataset.prepare(device=device);\n",
    "valdataset.prepare(device=device)\n",
    "system = Structured(traindataset, *trainer.gadgetry())\n",
    "system.mechanize() # sync for gears and spaces\n",
    "mech = system.mechanics()\n",
    "model.prepare(device=device);\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "model.load_checkpoint(path=loc.joinpath('model'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_img_ids = valdataset.get_image_id(np.arange(valdataset.size))\n",
    "# safe_ids = set(fiids.tolist()).intersection(set(val_img_ids.tolist()))\n",
    "# len(val_img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_img_ids = valdataset.get_image_id(np.arange(valdataset.size))\n",
    "# fiids = fullddata.get_image_id(np.arange(fullddata.size))\n",
    "# fiid_map = {fiid: i for i, fiid in enumerate(fiids)}\n",
    "# # inds = np.array([fiid_map[fiid] for fiid in safe_ids])\n",
    "# # inds.sort()\n",
    "# # save_json(inds.tolist(), 'save_inds.json')\n",
    "# inds = load_json('save_inds.json')\n",
    "# inds = np.array(inds)\n",
    "# len(inds), inds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valemb = model.encode(valbatch['image_features'])\n",
    "# lbls = valbatch['label']\n",
    "# valemb.shape, lbls.shape\n",
    "# # lbl = 40\n",
    "# # lbls[:, lbl].sum()\n",
    "# # pos = emb[lbls[:, lbl]]\n",
    "# # proj = pos.T @ pos / lbls[:, lbl].sum()\n",
    "# # proj.shape\n",
    "# projs = []\n",
    "# for lbl in range(lbls.shape[1]):\n",
    "#     pos = valemb[lbls[:, lbl]]\n",
    "#     proj = pos.T @ pos / lbls[:, lbl].sum()\n",
    "#     projs.append(proj)\n",
    "# projs.append(torch.eye(valemb.shape[1], device=valemb.device))\n",
    "# projs = torch.stack(projs)\n",
    "# projs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4135"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valfulldata = COCO(eval_split=-0.1, dataroot=syscfg.pull('dataroot'))\n",
    "# fullddata = COCO(eval_split=None, split='val')\n",
    "valfulldata.prepare(device=device);\n",
    "fiids = valfulldata.get_image_id(np.arange(valfulldata.size))\n",
    "valmap = {}\n",
    "for i, im in enumerate(fiids.tolist()):\n",
    "    valmap.setdefault(im, []).append(i)\n",
    "val_img_ids = set(valdataset.get_image_id(np.arange(valdataset.size)).tolist())\n",
    "valpicks = np.array([options[0] for key, options in valmap.items() if key in val_img_ids])\n",
    "len(valpicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = valpicks\n",
    "valbatch = Context(valfulldata, DictGadget({'index': inds, 'size': len(inds)}))\n",
    "valbatch\n",
    "\n",
    "vscore = model.predict(model.encode(valbatch['image_features']))\n",
    "vy = valbatch['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5797434d295d479dbe358557c492370d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.9802548331114336, -3.3900856971740723, 0.5113652348869506)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs = []\n",
    "thresholds = []\n",
    "f1s = []\n",
    "for ci in tqdm(range(valdataset.label_space.n)):\n",
    "    points = vscore[:, ci].cpu().numpy()\n",
    "    gtlabels = vy[:, ci].cpu().numpy()\n",
    "\n",
    "    threshold = roc_threshold(points[gtlabels], points[~gtlabels])\n",
    "    thresholds.append(threshold)\n",
    "    f1 = f1_score(gtlabels, points > threshold)\n",
    "    f1s.append(f1)\n",
    "    aucs.append(roc_auc_score(gtlabels, points))\n",
    "vaucs = torch.as_tensor(aucs).to(device)\n",
    "vthresholds = torch.as_tensor(thresholds).to(device)\n",
    "vf1s = torch.as_tensor(f1s).to(device)\n",
    "vaucs.mean().item(), vthresholds.mean().item(), vf1s.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifier = ConceptAlgebra(as_delta=False)\n",
    "modifier.extract_projections(model.encode(valbatch['image_features']), valbatch['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(COCO[25014](index, text_features, label, image_id, caption_id, caption, image, image_features),\n",
       " 5000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set\n",
    "fullddata = COCO(eval_split=None, split='val', dataroot=syscfg.pull('dataroot'))\n",
    "fullddata.prepare(device=device);\n",
    "fiids = fullddata.get_image_id(np.arange(fullddata.size))\n",
    "idmap = {}\n",
    "for i, im in enumerate(fiids.tolist()):\n",
    "    idmap.setdefault(im, []).append(i)\n",
    "picks = np.array([options[0] for options in idmap.values()])\n",
    "fullddata, len(picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = picks\n",
    "batch = Context(fullddata, DictGadget({'index': inds, 'size': len(inds)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 80])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = model.encode(batch['image_features'])\n",
    "y = batch['label']\n",
    "num_classes = fullddata.label_space.n\n",
    "\n",
    "score = model.predict(z)\n",
    "yhat = score > vthresholds.unsqueeze(0)\n",
    "valid = y.eq(yhat)\n",
    "valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9661585288104874 0.8858969480356834 0.4750030243125334 0.1 0.35273242170661656 0.8783542448585606 182.8875\n"
     ]
    }
   ],
   "source": [
    "obs_auc = []\n",
    "obs_pres, obs_recs, obs_f1s, obs_sup = [], [], [], []\n",
    "for ic in range(num_classes):\n",
    "    auc = roc_auc_score(y[:, ic].cpu().numpy(), score[:, ic].cpu().numpy())\n",
    "    obs_auc.append(auc)\n",
    "    (_,pre), (_,rec), (_,f1), (_,sup) = precision_recall_fscore_support(y[:, ic].cpu().numpy(), score[:, ic].cpu().numpy() > vthresholds[ic].item())\n",
    "    obs_pres.append(pre.item())\n",
    "    obs_recs.append(rec.item())\n",
    "    obs_f1s.append(f1.item())\n",
    "    obs_sup.append(sup.item())\n",
    "obs_auc = np.array(obs_auc)\n",
    "obs_pres = np.array(obs_pres)\n",
    "obs_recs = np.array(obs_recs)\n",
    "obs_f1s = np.array(obs_f1s)\n",
    "obs_sup = np.array(obs_sup)\n",
    "print(obs_auc.mean(), obs_auc.min(), obs_f1s.mean(), obs_f1s.min(), obs_pres.mean(), obs_recs.mean(), obs_sup.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gti = ClassLevelLabelIntervention()\n",
    "def compute_interventional_metrics(iy, iscore):\n",
    "    iyhat = iscore > vthresholds.unsqueeze(0)\n",
    "\n",
    "    changed_mask = iy != y\n",
    "    assert changed_mask.any(), f'nothing changed'\n",
    "    \n",
    "    correct = iy == iyhat\n",
    "\n",
    "    sel = changed_mask\n",
    "    sel = changed_mask & valid\n",
    "    # (_,c_pre), (_,c_rec), (_,c_f1), (_, c_supp) = precision_recall_fscore_support(torch.ones_like(correct[sel]).cpu().numpy(), correct[sel].cpu().numpy()) # adding and removing are both counted as positive\n",
    "    (_,c_pre), (_,c_rec), (_,c_f1), (_, c_supp) = precision_recall_fscore_support(iy[sel].cpu().numpy(), iyhat[sel].cpu().numpy())\n",
    "    c_acc = correct[sel].float().mean().item()\n",
    "\n",
    "    sel = ~changed_mask\n",
    "    sel = ~changed_mask & valid\n",
    "    (_,u_pre), (_,u_rec), (_,u_f1), (_, u_supp) = precision_recall_fscore_support(iy[sel].cpu().numpy(), iyhat[sel].cpu().numpy())\n",
    "    u_acc = correct[sel].float().mean().item()\n",
    "\n",
    "    return c_pre, c_rec, c_f1, c_acc, u_pre, u_rec, u_f1, u_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b47e9ef5c7048b58b64e7bcf9a42b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2229bf6e41947389b8baf5e5926dfe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab93b38b3f724f6bbaf0e42e26c0be9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8681683599948883 0.07379415798093494\n",
      "0.9962291628122331 0.0696306178257842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/felix/miniconda3/envs/work/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# interventions (training)\n",
    "torch.manual_seed(11)\n",
    "\n",
    "num_intv_per_sample = 10\n",
    "\n",
    "c_accs, u_accs = [], []\n",
    "c_f1s, c_pres, c_recs, c_supps = [], [], [], []\n",
    "u_f1s, u_pres, u_recs, u_supps = [], [], [], []\n",
    "\n",
    "for _ in tqdm(range(num_intv_per_sample)):\n",
    "    adds, rems = None, None\n",
    "    adds = gti.sample_add_intervention(y)\n",
    "    rems = gti.sample_remove_intervention(y)\n",
    "    \n",
    "    iz = modifier.apply_intervention(z, adds, rems)\n",
    "    iscore = model.predict(iz)\n",
    "    iy = gti.apply_intervention(y, adds, rems)\n",
    "    \n",
    "    c_pre, c_rec, c_f1, c_acc, u_pre, u_rec, u_f1, u_acc = compute_interventional_metrics(iy, iscore)\n",
    "    c_accs.append(c_acc); c_f1s.append(c_f1); c_pres.append(c_pre); c_recs.append(c_rec)\n",
    "    u_accs.append(u_acc); u_f1s.append(u_f1); u_pres.append(u_pre); u_recs.append(u_rec)\n",
    "\n",
    "# print(np.array(c_accs).mean(), np.array(u_accs).mean())\n",
    "# print(np.array(c_f1s).mean(), np.array(c_f1s).std(), np.array(c_pres).mean(), np.array(c_recs).mean())\n",
    "# print(np.array(u_f1s).mean(), np.array(u_f1s).std(), np.array(u_pres).mean(), np.array(u_recs).mean())\n",
    "# print(np.array(c_accs).mean(), np.array(c_f1s).mean(), np.array(u_f1s).mean())\n",
    "itrain_c_acc = np.array(c_accs).mean()\n",
    "itrain_u_f1 = np.array(u_f1s).mean()\n",
    "\n",
    "\n",
    "# interventions (not seen during training)\n",
    "torch.manual_seed(11)\n",
    "\n",
    "c_accs, u_accs = [], []\n",
    "c_f1s, c_pres, c_recs, c_supps = [], [], [], []\n",
    "u_f1s, u_pres, u_recs, u_supps = [], [], [], []\n",
    "\n",
    "for _ in tqdm(range(num_intv_per_sample)):\n",
    "    adds, rems = None, None\n",
    "    adds = gti.sample_add_intervention(y)\n",
    "    # rems = gti.sample_remove_intervention(y)\n",
    "    \n",
    "    iz = modifier.apply_intervention(z, adds, rems)\n",
    "    iscore = model.predict(iz)\n",
    "    iy = gti.apply_intervention(y, adds, rems)\n",
    "    \n",
    "    c_pre, c_rec, c_f1, c_acc, u_pre, u_rec, u_f1, u_acc = compute_interventional_metrics(iy, iscore)\n",
    "    c_accs.append(c_acc); c_f1s.append(c_f1); c_pres.append(c_pre); c_recs.append(c_rec)\n",
    "    u_accs.append(u_acc); u_f1s.append(u_f1); u_pres.append(u_pre); u_recs.append(u_rec)\n",
    "\n",
    "# print(np.array(c_accs).mean(), np.array(u_accs).mean())\n",
    "# print(np.array(c_f1s).mean(), np.array(c_f1s).std(), np.array(c_pres).mean(), np.array(c_recs).mean())\n",
    "# print(np.array(u_f1s).mean(), np.array(u_f1s).std(), np.array(u_pres).mean(), np.array(u_recs).mean())\n",
    "# print(np.array(c_accs).mean(), np.array(c_f1s).mean(), np.array(u_f1s).mean())\n",
    "iadd_c_acc = np.array(c_accs).mean()\n",
    "iadd_u_f1 = np.array(u_f1s).mean()\n",
    "\n",
    "\n",
    "# interventions (not seen during training)\n",
    "torch.manual_seed(11)\n",
    "\n",
    "num_intv_per_sample = 10\n",
    "\n",
    "c_accs, u_accs = [], []\n",
    "c_f1s, c_pres, c_recs, c_supps = [], [], [], []\n",
    "u_f1s, u_pres, u_recs, u_supps = [], [], [], []\n",
    "\n",
    "for _ in tqdm(range(num_intv_per_sample)):\n",
    "    adds, rems = None, None\n",
    "    # adds = gti.sample_add_intervention(y)\n",
    "    rems = gti.sample_remove_intervention(y)\n",
    "    \n",
    "    iz = modifier.apply_intervention(z, adds, rems)\n",
    "    iscore = model.predict(iz)\n",
    "    iy = gti.apply_intervention(y, adds, rems)\n",
    "    \n",
    "    c_pre, c_rec, c_f1, c_acc, u_pre, u_rec, u_f1, u_acc = compute_interventional_metrics(iy, iscore)\n",
    "    c_accs.append(c_acc); c_f1s.append(c_f1); c_pres.append(c_pre); c_recs.append(c_rec)\n",
    "    u_accs.append(u_acc); u_f1s.append(u_f1); u_pres.append(u_pre); u_recs.append(u_rec)\n",
    "\n",
    "# print(np.array(c_accs).mean(), np.array(u_accs).mean())\n",
    "# print(np.array(c_f1s).mean(), np.array(c_f1s).std(), np.array(c_pres).mean(), np.array(c_recs).mean())\n",
    "# print(np.array(u_f1s).mean(), np.array(u_f1s).std(), np.array(u_pres).mean(), np.array(u_recs).mean())\n",
    "# print(np.array(c_accs).mean(), np.array(c_f1s).mean(), np.array(u_f1s).mean())\n",
    "irem_c_acc = np.array(c_accs).mean()\n",
    "irem_u_f1 = np.array(u_f1s).mean()\n",
    "\n",
    "igen_c_acc = (iadd_c_acc + irem_c_acc) / 2\n",
    "igen_u_f1 = (iadd_u_f1 + irem_u_f1) / 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9661585288104874 0.8858969480356834 0.4750030243125334 0.1\n",
      "0.8681683599948883 0.07379415798093494\n",
      "0.9962291628122331 0.0696306178257842\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(obs_auc.mean(), obs_auc.min(), obs_f1s.mean(), obs_f1s.min())\n",
    "print(itrain_c_acc, itrain_u_f1)\n",
    "print(igen_c_acc, igen_u_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for parity in tqdm(range(num_intv_per_sample)):\n",
    "#     adds = gti.sample_add_intervention(y)\n",
    "#     rems = gti.sample_remove_intervention(y)\n",
    "#     rems[:] = -1\n",
    "#     # adds[:] = -1\n",
    "    \n",
    "#     iz = modifier.apply_intervention(z, adds, rems)\n",
    "#     iscore = model.predict(iz)\n",
    "#     iyhat = iscore > vthresholds.unsqueeze(0)\n",
    "\n",
    "#     iy = gti.apply_intervention(y, adds, rems)\n",
    "#     changed_mask = iy != y\n",
    "#     # row_ind = torch.arange(len(iscore), device=device)[adds>0]\n",
    "#     # row_ind = torch.cat([row_ind, torch.arange(len(iscore), device=device)[rems>0]])\n",
    "#     # col_ind = torch.cat([adds[adds>0], rems[rems>0]])\n",
    "#     # changed_mask = torch.zeros_like(iscore)\n",
    "#     # changed_mask[row_ind, col_ind] = 1\n",
    "#     # changed_mask = changed_mask.bool()\n",
    "\n",
    "#     correct = iy == iyhat\n",
    "\n",
    "#     sel = changed_mask\n",
    "#     sel = changed_mask & valid\n",
    "#     (_,c_pre), (_,c_rec), (_,c_f1), (_, c_supp) = precision_recall_fscore_support(torch.ones_like(correct[sel]).cpu().numpy(), correct[sel].cpu().numpy())\n",
    "#     # (_,c_pre), (_,c_rec), (_,c_f1), (_, c_supp) = precision_recall_fscore_support(iy[sel].cpu().numpy(), iyhat[sel].cpu().numpy())\n",
    "#     c_pre, c_rec, c_f1, c_supp = c_pre.item(), c_rec.item(), c_f1.item(), c_supp.item()\n",
    "#     c_acc = (iy[sel] == iyhat[sel]).float().mean().item()\n",
    "#     c_accs.append(c_acc); c_f1s.append(c_f1); c_pres.append(c_pre); c_recs.append(c_rec); c_supps.append(c_supp)\n",
    "\n",
    "#     sel = ~changed_mask\n",
    "#     sel = ~changed_mask & valid\n",
    "#     (_,u_pre), (_,u_rec), (_,u_f1), (_, u_supp) = precision_recall_fscore_support(iy[sel].cpu().numpy(), iyhat[sel].cpu().numpy())\n",
    "#     u_pre, u_rec, u_f1, u_supp = u_pre.item(), u_rec.item(), u_f1.item(), u_supp.item()\n",
    "#     u_acc = (iy[sel] == iyhat[sel]).float().mean().item()\n",
    "#     u_accs.append(u_acc); u_f1s.append(u_f1); u_pres.append(u_pre); u_recs.append(u_rec); u_supps.append(u_supp)\n",
    "    \n",
    "# c_accs = np.array(c_accs); u_accs = np.array(u_accs)\n",
    "# c_f1s = np.array(c_f1s); c_pres = np.array(c_pres); c_recs = np.array(c_recs); c_supps = np.array(c_supps)\n",
    "# u_f1s = np.array(u_f1s); u_pres = np.array(u_pres); u_recs = np.array(u_recs); u_supps = np.array(u_supps)\n",
    "# print(c_accs.mean(), u_accs.mean())\n",
    "# print(c_f1s.mean(), c_f1s.std(), c_pres.mean(), c_recs.mean(), c_supps.mean())\n",
    "# print(u_f1s.mean(), u_f1s.std(), u_pres.mean(), u_recs.mean(), u_supps.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "iyhat = iscore > vthresholds.unsqueeze(0)\n",
    "\n",
    "changed_mask = iy != y\n",
    "assert changed_mask.any(), f'nothing changed'\n",
    "\n",
    "correct = iy == iyhat\n",
    "\n",
    "sel = changed_mask\n",
    "sel = changed_mask & valid\n",
    "# (_,c_pre), (_,c_rec), (_,c_f1), (_, c_supp) = precision_recall_fscore_support(torch.ones_like(correct[sel]).cpu().numpy(), correct[sel].cpu().numpy()) # adding and removing are both counted as positive\n",
    "(_,c_pre), (_,c_rec), (_,c_f1), (_, c_supp) = precision_recall_fscore_support(iy[sel].cpu().numpy(), iyhat[sel].cpu().numpy())\n",
    "c_acc = correct[sel].float().mean().item()\n",
    "\n",
    "# sel = ~changed_mask\n",
    "# sel = ~changed_mask & valid\n",
    "# (_,u_pre), (_,u_rec), (_,u_f1), (_, u_supp) = precision_recall_fscore_support(iy[sel].cpu().numpy(), iyhat[sel].cpu().numpy())\n",
    "# u_acc = correct[sel].float().mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True,  ..., True, True, True], device='cuda:1')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct[sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhat valid\n",
    "iyhat = iscore > vthresholds.unsqueeze(0)\n",
    "correct = iy.eq(iyhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8786563873291016"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy averaged across classes in observational distribution\n",
    "valid.mul(y).float().sum(0).div(y.float().sum(0)).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8805, device='cuda:1'), tensor(0.9259, device='cuda:1'))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy of changed, accuracy of unchanged\n",
    "correct[changed_mask & valid].float().mean(), correct[~changed_mask & valid].float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.78748628, 0.99591392]),\n",
       " array([0.99583565, 0.79065744]),\n",
       " array([0.87949001, 0.88149488]),\n",
       " array([3602, 4624]))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(iy[changed_mask & valid].cpu().numpy(), iyhat[changed_mask & valid].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.97873884, 0.05217978]),\n",
       " array([0.94472459, 0.12913235]),\n",
       " array([0.96143097, 0.07432595]),\n",
       " array([355565,   8379]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(iy[~changed_mask & valid].cpu().numpy(), iyhat[~changed_mask & valid].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ci = 7\n",
    "# ci = random.randint(0, len(valdataset.label_space.class_names)-1)\n",
    "# # ci = 0\n",
    "# # print(valdataset.label_space.class_names[ci])\n",
    "\n",
    "# # plot the roc curve\n",
    "# positives = vscore[vy[:, ci], ci].cpu().numpy()\n",
    "# negatives = vscore[~vy[:, ci], ci].cpu().numpy()\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(np.concatenate([np.ones(len(positives)), np.zeros(len(negatives))]),\n",
    "#                                     np.concatenate([positives, negatives]))\n",
    "# plt.plot(fpr, tpr, label='ROC curve')\n",
    "# plt.title(valdataset.label_space.class_names[ci])\n",
    "\n",
    "# points = vscore\n",
    "# gtlabels = vl\n",
    "\n",
    "# p_samples = points[gtlabels[:, ci], ci].cpu().numpy()\n",
    "# n_samples = points[~gtlabels[:, ci], ci].cpu().numpy()\n",
    "# samples = np.concatenate([p_samples, n_samples])\n",
    "# gt = np.concatenate([np.ones(len(p_samples)), np.zeros(len(n_samples))])\n",
    "\n",
    "\n",
    "# plt.hist(p_samples, bins=100, alpha=0.5, label='original');\n",
    "# plt.hist(n_samples, bins=100, alpha=0.5, label='original');\n",
    "\n",
    "# f1s = []\n",
    "# leg = []\n",
    "# for i, threshold_fn in enumerate([roc_threshold, bayes_threshold]):\n",
    "#     threshold = threshold_fn(p_samples, n_samples)\n",
    "#     # print(f\"{threshold_fn.__name__} threshold: {threshold:.3f}\")\n",
    "#     f1 = f1_score(gt, samples > threshold)\n",
    "#     plt.axvline(threshold, label=f\"{threshold_fn.__name__} threshold\", c=f'C{i}', linestyle='--')\n",
    "#     # add the f1 to the legend\n",
    "#     f1s.append(f1)\n",
    "#     leg.append(mpatches.Patch(color=f'C{i}', label=f\"{threshold_fn.__name__} threshold (F1={f1:.3f})\"))\n",
    "# # sorted by f1\n",
    "# plt.title(valdataset.label_space.class_names[ci])\n",
    "# plt.legend(handles=[leg[i] for i in np.argsort(f1s)[::-1]]);\n",
    "# plt.tight_layout();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def other_inds(N, r1, r2=None):\n",
    "#     full = torch.arange(1,N,device=r1.device).unsqueeze(0).expand(r1.shape[0], -1).clone()\n",
    "    \n",
    "#     m1 = r1.view(-1, 1)\n",
    "#     if r2 is None:\n",
    "#         return full.sub(r1.view(-1, 1)).remainder(N)\n",
    "    \n",
    "#     m2 = r2.view(-1, 1)\n",
    "#     return full.add(m2-m1-1).remainder(N-1)[:,:-1].add(m1+1).remainder(N)\n",
    "# c_inds = torch.stack([adds, rems], dim=-1)\n",
    "# u_inds = other_inds(80, adds, rems)\n",
    "# c_inds.shape, u_inds.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index -1 is out of bounds for dimension 1 with size 80",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# select the elements corresponding to c_inds in iscore\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m c_score \u001b[38;5;241m=\u001b[39m \u001b[43miscore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_inds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m c_score\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index -1 is out of bounds for dimension 1 with size 80"
     ]
    }
   ],
   "source": [
    "# select the elements corresponding to c_inds in iscore\n",
    "c_score = iscore.cpu().gather(1, c_inds.cpu())\n",
    "c_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "         19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "         37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
       "         55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "         73, 74, 75, 76, 77, 78, 79]])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 80\n",
    "r1 = torch.tensor([0])\n",
    "r2 = torch.tensor([1])\n",
    "full = torch.arange(1,N).unsqueeze(0).expand(r1.shape[0], -1).clone()\n",
    "m1 = r1.view(-1, 1)\n",
    "m2 = r2.view(-1, 1)\n",
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9, 19 -> 9, 10 True\n",
      "{9, 19}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,\n",
       "        38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "        56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73,\n",
       "        74, 75, 76, 77, 78, 79,  0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12,\n",
       "        13, 14, 15, 16, 17, 18])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "    # modulo 80\n",
    "    i, j = adds[0].item(), removes[0].item()\n",
    "    # print(i,j)\n",
    "    i = random.randint(0, 79)\n",
    "    j = random.randint(0, 78) + i\n",
    "    j = j % 80\n",
    "    # i = 3\n",
    "    # j = 0\n",
    "    i, j\n",
    "    i, j = (i, j) if i < j else (j, i)\n",
    "    s1, s2 = j-i-1, i+1\n",
    "    sel = torch.arange(1,80).add(s1).remainder(79)[:-1].add(s2).remainder(80)\n",
    "    assert j not in sel.tolist() and i not in sel.tolist()\n",
    "# sel[:-1].add_(2).remainder_(80)\n",
    "# print(len(sel))\n",
    "# 71, 3 -> 11, 72\n",
    "# 53, 51 -> 77, 54\n",
    "# 0, 1 -> 0, 1\n",
    "# 0, 10 -> 9, 1\n",
    "# 0, 79 -> 78, 1\n",
    "# 1, 79 -> 77, 2\n",
    "# 1, 0 -> -1, 2\n",
    "# 1, 0 -> 78, 2\n",
    "# 2, 0 -> -2, 3\n",
    "print(f'{i}, {j} -> {s1}, {s2} {i not in sel.tolist() and j not in sel.tolist()}')\n",
    "print({x for x in range(80)} - set(sel.tolist()))\n",
    "sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════╤═══════╤══════════╕\n",
      "│          │   add │   remove │\n",
      "╞══════════╪═══════╪══════════╡\n",
      "│ original │    -9 │        5 │\n",
      "├──────────┼───────┼──────────┤\n",
      "│ delta    │    -6 │      -40 │\n",
      "├──────────┼───────┼──────────┤\n",
      "│ end      │   -16 │      -35 │\n",
      "╘══════════╧═══════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0, len(iz)-1)\n",
    "\n",
    "delta = iscore.sub(score)\n",
    "addi = adds[i].item()\n",
    "remi = removes[i].item()\n",
    "# print(addi, remi)\n",
    "print(tabulate([('original', score[i, addi].cpu().int().numpy(), score[i,remi].cpu().int().numpy()),\n",
    "('delta', delta[i,addi].int().cpu().numpy(), delta[i,remi].int().cpu().numpy()),\n",
    "('end', iscore[i, addi].cpu().int().numpy(), iscore[i,remi].cpu().int().numpy())], headers=['', 'add', 'remove'], tablefmt='fancy_grid'))\n",
    "\n",
    "# print(delta[i].int().cpu().numpy())\n",
    "# print(y[i].cpu().numpy())\n",
    "# print(score[i].cpu().int().numpy())\n",
    "# print(score[i].ge(0).cpu().numpy())\n",
    "# print(iscore[i].cpu().int().numpy())\n",
    "# print(iscore[i].ge(0).cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False,  True, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adds[0].item(), removes[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('person',\n",
       " 'bicycle',\n",
       " 'car',\n",
       " 'motorcycle',\n",
       " 'airplane',\n",
       " 'bus',\n",
       " 'train',\n",
       " 'truck',\n",
       " 'boat',\n",
       " 'traffic light',\n",
       " 'fire hydrant',\n",
       " 'stop sign',\n",
       " 'parking meter',\n",
       " 'bench',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'sheep',\n",
       " 'cow',\n",
       " 'elephant',\n",
       " 'bear',\n",
       " 'zebra',\n",
       " 'giraffe',\n",
       " 'backpack',\n",
       " 'umbrella',\n",
       " 'handbag',\n",
       " 'tie',\n",
       " 'suitcase',\n",
       " 'frisbee',\n",
       " 'skis',\n",
       " 'snowboard',\n",
       " 'sports ball',\n",
       " 'kite',\n",
       " 'baseball bat',\n",
       " 'baseball glove',\n",
       " 'skateboard',\n",
       " 'surfboard',\n",
       " 'tennis racket',\n",
       " 'bottle',\n",
       " 'wine glass',\n",
       " 'cup',\n",
       " 'fork',\n",
       " 'knife',\n",
       " 'spoon',\n",
       " 'bowl',\n",
       " 'banana',\n",
       " 'apple',\n",
       " 'sandwich',\n",
       " 'orange',\n",
       " 'broccoli',\n",
       " 'carrot',\n",
       " 'hot dog',\n",
       " 'pizza',\n",
       " 'donut',\n",
       " 'cake',\n",
       " 'chair',\n",
       " 'couch',\n",
       " 'potted plant',\n",
       " 'bed',\n",
       " 'dining table',\n",
       " 'toilet',\n",
       " 'tv',\n",
       " 'laptop',\n",
       " 'mouse',\n",
       " 'remote',\n",
       " 'keyboard',\n",
       " 'cell phone',\n",
       " 'microwave',\n",
       " 'oven',\n",
       " 'toaster',\n",
       " 'sink',\n",
       " 'refrigerator',\n",
       " 'book',\n",
       " 'clock',\n",
       " 'vase',\n",
       " 'scissors',\n",
       " 'teddy bear',\n",
       " 'hair drier',\n",
       " 'toothbrush')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdataset.label_space.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 80])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "ic = 2\n",
    "y[:,ic].float().mean()\n",
    "\n",
    "dz = z @ projs[ic]\n",
    "dz = z + (-1) ** y[:,ic].unsqueeze(-1) * dz\n",
    "dz = dz / dz.norm(dim=-1, keepdim=True)\n",
    "dz.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80,), (80, 80))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_results = []\n",
    "intv_results = []\n",
    "\n",
    "obs_score = model.predict(z).cpu().numpy()\n",
    "\n",
    "for ic in tqdm(range(y.shape[1])):\n",
    "    dz = z @ projs[ic]\n",
    "    dz = z + (-1) ** y[:,ic].unsqueeze(-1) * dz\n",
    "    dz = dz / dz.norm(dim=-1, keepdim=True)\n",
    "    intv_score = model.predict(dz).cpu().numpy()\n",
    "    obs_results.append(roc_auc_score(gt, obs_score[:, i]))\n",
    "    intv_row = []\n",
    "    for i in range(y.shape[1]):\n",
    "        gt = y[:, i].cpu().numpy()\n",
    "        if i == ic:\n",
    "            gt = ~gt\n",
    "        intv_row.append(roc_auc_score(gt, intv_score[:, i]))\n",
    "    intv_results.append(intv_row)\n",
    "obs_results = np.array(obs_results)\n",
    "intv_results = np.array(intv_results)\n",
    "obs_results.shape, intv_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  9.1324,  -9.0957, -11.5980, -13.6753, -15.8401, -17.5224, -11.4130,\n",
       "        -10.6889,  -9.6972, -12.5531, -19.4821, -16.7362, -18.4169,  -8.7252,\n",
       "        -11.3438,  -8.1346,  -8.7017,  -8.9816, -15.1360, -16.9146, -14.9189,\n",
       "        -13.8886, -17.9677, -13.7450,  -7.1458, -11.8310,  -5.7632,  -7.5476,\n",
       "        -10.2915, -14.5164, -22.3432, -23.1013, -12.3706, -22.9805, -13.9289,\n",
       "        -18.5452, -22.8026, -20.0341, -11.0255,  -0.3999,  -6.2802,  -0.1928,\n",
       "         -8.1223,  -6.1516,  -6.1214,  -2.8473, -10.8983,  -6.5904, -11.2488,\n",
       "         -7.8607, -17.4817, -12.2376, -13.9882, -16.8319, -15.4528, -13.8059,\n",
       "         -5.0010,  -7.1793,   0.6025,  -6.3523,  -8.7216,  -0.9808,  -8.0420,\n",
       "         -6.2589, -13.6159,  -7.4622, -11.5423,  -1.2052,  -9.2549,  -9.9871,\n",
       "        -12.3797,   5.3217, -10.4644,  -2.8025,  -4.4475,  -0.2001,  -5.8738,\n",
       "         -7.3922,  -3.4281,  -1.3222], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(emb)[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = (projs[-4] - projs[-5]) @ emb[idx]\n",
    "new = new / new.norm()\n",
    "new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  3.9024, -10.6718,  -6.7774, -13.5819,  -5.4185,  -5.7317, -10.2014,\n",
       "          -8.8080, -14.0354,  -9.1711, -16.1837,  -8.8150, -13.6464, -10.6974,\n",
       "          -6.5013, -16.7903, -10.8953, -11.2102, -15.7333,  -9.0341, -13.8807,\n",
       "         -17.1458, -19.8320, -17.6132,  -6.9916, -12.8268,  -8.4250, -12.4215,\n",
       "         -12.9349,  -9.5340, -12.5550, -14.9554, -10.9486,  -7.8032, -15.0483,\n",
       "         -12.4928, -14.6519, -15.7950, -19.9726,  -8.9246, -21.3170, -14.5983,\n",
       "          -9.4339,  -6.3230, -10.8002,  -8.1817, -10.1597, -11.4045,  -9.9101,\n",
       "         -14.0311, -13.2979,  -7.0450, -10.4698, -13.5920, -16.6083,  -6.0683,\n",
       "         -13.4473, -19.2462, -16.3298, -23.2252, -12.8410, -21.5716, -14.6681,\n",
       "         -14.6640, -12.4886, -14.2852, -11.2389,  -8.4424, -14.2416, -15.9075,\n",
       "          -8.9048, -10.5014, -15.6897, -11.2378, -14.1076, -27.9013,   0.8805,\n",
       "         -14.6172, -19.6178, -15.6648]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4135, 80])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(emb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9789, device='cuda:0', dtype=torch.float64),\n",
       " tensor(-3.2697, device='cuda:0'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(emb)\n",
    "i = 0\n",
    "thrs = []\n",
    "aucs = []\n",
    "for i in range(pred.shape[1]):\n",
    "    fpr, tpr, thresholds = roc_curve(lbls[:,i].cpu().numpy(), pred[:,i].cpu().numpy())\n",
    "    auc = roc_auc_score(lbls[:,i].cpu().numpy(), pred[:,i].cpu().numpy())\n",
    "    thr = thresholds[(tpr-fpr).argmax()]\n",
    "    thrs.append(thr)\n",
    "    aucs.append(auc)\n",
    "thrs = torch.as_tensor(thrs).to(device)\n",
    "vaucs = torch.as_tensor(aucs).to(device)\n",
    "vaucs.mean(), thrs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 80])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = model.encode(batch['image_features'])\n",
    "y = batch['label']\n",
    "score = model.predict(z)\n",
    "yp = score.sub(thrs.unsqueeze(0)).ge(0)\n",
    "score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9674, device='cuda:2', dtype=torch.float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "aucs = []\n",
    "for i in range(pred.shape[1]):\n",
    "    auc = roc_auc_score(y[:,i].cpu().numpy(), score[:,i].cpu().numpy())\n",
    "    aucs.append(auc)\n",
    "aucs = torch.as_tensor(aucs).to(device)\n",
    "aucs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.2764505119453925)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y[:,idx].cpu().numpy(), yp[:,idx].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 3])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs = []\n",
    "for idx in range(y.shape[1]):\n",
    "    p, r, f, _ = precision_recall_fscore_support(y[:,idx].cpu().numpy(), yp[:,idx].cpu().numpy())\n",
    "    outs.append((p[1], r[1], f[1]))\n",
    "outs = torch.as_tensor(outs).to(device)\n",
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9073, 0.2378, 0.5214, 0.5544, 0.8257, 0.5926, 0.6576, 0.4215, 0.6176,\n",
       "        0.3743, 0.2765, 0.1743, 0.1308, 0.2748, 0.2030, 0.7054, 0.3593, 0.5011,\n",
       "        0.6087, 0.4420, 0.9438, 0.7500, 0.9390, 0.8919, 0.3023, 0.3384, 0.3568,\n",
       "        0.4231, 0.2056, 0.4862, 0.8679, 0.4653, 0.5704, 0.7330, 0.6690, 0.8597,\n",
       "        0.6244, 0.8581, 0.9174, 0.4437, 0.3298, 0.4681, 0.3543, 0.4094, 0.3725,\n",
       "        0.4373, 0.4373, 0.2147, 0.4462, 0.2431, 0.4769, 0.4409, 0.2479, 0.7949,\n",
       "        0.3661, 0.4580, 0.5067, 0.3570, 0.1854, 0.4668, 0.5943, 0.6712, 0.5326,\n",
       "        0.5668, 0.6884, 0.5345, 0.4138, 0.3149, 0.1889, 0.4283, 0.2286, 0.6654,\n",
       "        0.4093, 0.3803, 0.2857, 0.3659, 0.1366, 0.4501, 0.0613, 0.1299],\n",
       "       device='cuda:2', dtype=torch.float64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs[:, -1]#.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.86018117, 0.95002032]),\n",
       " array([0.94668401, 0.86817675]),\n",
       " array([0.90136195, 0.9072565 ]),\n",
       " array([2307, 2693]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
